{
 "metadata": {
  "name": "",
  "signature": "sha256:b58d1fef0db1050fd494a91659169095f9a296de511f8e821ac3b593f8a7cdef"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image, HTML\n",
      "Image(url='http://higgsml.lal.in2p3.fr/files/2014/05/cropped-HML-Higgs-ML-banner1.png', embed=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction\n",
      "\n",
      "For this practical session, we will (virtually) participate in the [Higgs challenge](https://www.kaggle.com/c/higgs-boson/). \n",
      "\n",
      "For this, we will need some machine learning artillery; in particular, we will be using a `python` library called [`scikit-learn`](http://scikit-learn.org/stable/). \n",
      "\n",
      "This library comes with several machine learning algorithms, however, we will only be using a couple of them for the purpose of the session.\n",
      "\n",
      "**N.B.** Feel free to explore the library and use the algorithms of your choice in case you feel the urgent and irresistible need to.\n",
      "\n",
      "## The goal\n",
      "\n",
      "- (Soft) Introduction to `python` and the `ipython notebook` \n",
      "- Play around with some classification learning algorithms, namely, ensemble algorithms.\n",
      "- (Geekily) Admire some nice plots generated after the learning.\n",
      "- Maximize the AMS, the objective function of the Higgs challenge. \n",
      "\n",
      "## Important Note: \n",
      "If you are running this notebook from the server, duplicate this file in order to modify it. It's on the `File` menu, with the `Make a copy...` button.\n",
      "\n",
      "## You tools\n",
      "\n",
      "For the purpose of this practical session, we have prepared some *helper* classes and functions that are meant to... well... help us write less code inside this notebook. They are all in the `SOS_tools.py` file. \n",
      "\n",
      "## IPython notebook\n",
      "\n",
      "The tool you are currently using for running `python` lines of code is the `ipython notebook`. It has two modes: `command` and `edit` mode. By default, you are in `command` mode. Press enter to enter the `edit` mode and modify a cell, then,\n",
      "\n",
      "- press `shift+enter` to execute a cell a go the next one.\n",
      "- Or press `alt+enter` if you want to execute the current cell in place.\n",
      "\n",
      "You can always go back to `command` mode by pressing `Esc`. \n",
      "\n",
      "More generally, press `h` in `command` mode for an exhaustive list of keyboard shortcuts.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import SOS_tools as SOS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Other Imports and options"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Some lil' tweaks that make life more enjoyable\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.mpl_style', 'default') # Make the graphs a bit prettier\n",
      "pd.set_option('display.max_columns', None) # Otherwise, the columns will be truncated\n",
      "pd.set_option('display.max_rows', 35)\n",
      "rcParams['figure.figsize'] = (10.0, 6.0)\n",
      "rcParams['axes.linewidth'] = 2.5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Let's get started..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_filename = 'training.csv'\n",
      "data = SOS.HiggsData(train_filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Python, ipython notebook and the scientific libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.cleaned_describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Some more stats..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can display the individual feature histograms with the following function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.attributes_hist_grid()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now for displaying with more details one or more features, use the function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.attributes_hist(['PRI_tau_phi', 'PRI_tau_eta']) ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In particular, if you want to visualize the weights distribution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.weights_hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This first part is only meant to be illustrative. Thus, we will only use a subset of the data. The `scikit` library includes a modules named `ensemble`, it contains some of the most common boosting algorithms. In particular, we will use `AdaBoost` for this example. You can use the other algorihtms later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.ensemble as ens\n",
      "import sklearn.tree as tree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is **mandatory** in machine learning to keep some data points aside, in order to estimate the performance of the trained classifier *in nature*, i.e, on observations that were not used during the learning. We usually refer to this set by the **the test** set, by contrast with the **training** set. The test must never be used for any fitting or training."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "small_train_X, small_train_Y, small_train_W = data.get_data_fold('train', number=1000)\n",
      "small_test_X, small_test_Y, small_test_W = data.get_data_fold('test', number=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Learning \"too much\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adaboost_of = ens.AdaBoostClassifier(n_estimators=1000, base_estimator=tree.DecisionTreeClassifier(max_depth=1))\n",
      "adaboost_of.fit(small_train_X, small_train_Y) ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SOS.learning_curve_plot({'adaboost': adaboost_of}, \n",
      "                        small_test_X, small_test_Y, small_test_W,\n",
      "                        small_train_X, small_train_Y, small_train_W, \n",
      "                        log_scale=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Oh, Wait? Let's discuss what's happening... "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Now you know what the `_of` part in `adaboost_of` actually means... "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using all the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most of the learning algorithms, if not all of them, have hyperparameters that must be tuned for a given dataset in order to select the set of hyperparameters that offers the best performance. If the validation is done on the test set, it boils down to \"fitting\" the hyperparameters to this test set, which contradicts the very principle of having a test set. Thus, we often split the data into three folds, namely a training, a validation, and a test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.set_split_fractions((0.3, 0.3))\n",
      "train_X, train_Y, train_W = data.get_data_fold('train') \n",
      "valid_X, valid_Y, valid_W = data.get_data_fold('valid')\n",
      "test_X, test_Y, test_W = data.get_data_fold('test')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import inspect\n",
      "HTML('Here is the list of <code>scikit</code> ensemble algorithms: <br/> <code><ul><li>' + '</li><li>'.join(name for name, obj in inspect.getmembers(ens) if inspect.isclass(obj) and 'Classifier' in name)+'</li></ul></code>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All the algorithms share the `fit(X, Y)` method that starts the learning, as well as the `n_estimators` hyperparameter that specifies the number of base classifiers to be combined.\n",
      "\n",
      "\n",
      "In order to know the hyperparameters they accept, simply instanciate an algorithm and tape `shift+tab` within the parameters are, this auto-documentation is an ipython feature. You can also use the `help` function.\n",
      "\n",
      "#### Note \n",
      "Don't forget to include the weights of the examples in the learning. Simply add the option `sample_weight=` to the `fit` method. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ens.RandomForestClassifier # press shift+tab at the end of the class name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "help(ens.RandomForestClassifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "{random_forest = ens.RandomForestClassifier(n_estimators=100).fit(train_X, train_Y, sample_weight=train_W)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adaboost = ens.AdaBoostClassifier(n_estimators=100, \n",
      "                                  base_estimator=tree.DecisionTreeClassifier(max_depth=3)\n",
      "                                  ).fit(train_X, train_Y, sample_weight=train_W)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SOS.learning_curve_plot({'RandomForest100': random_forest, 'AdaBoost100': adaboost}, \n",
      "                        valid_X, valid_Y, valid_W,\n",
      "                        train_X, train_Y, train_W,\n",
      "                        log_scale=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The Approximate Median Significance\n",
      "$$\n",
      "\\text{AMS} = \\sqrt{ 2 \\left( (s + b + 10) \\ln \\left( 1 + \\frac{s}{b +\n",
      "    10} \\right) - s \\right) }\n",
      "$$\n",
      "`s` and `b` are the sum of signal and background weights, respectively, in the selection region."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_, valid_Y, unnormalized_valid_W = data.get_data_fold('valid', normed_weights=False)\n",
      "weight_factor = float(data.shape[0]) / valid_X.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ab_valid_scores = adaboost.predict_proba(valid_X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf_valid_scores = random_forest.predict_proba(valid_X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SOS.hist_scores(ab_valid_scores, valid_Y, weights=unnormalized_valid_W)\n",
      "# the options by default are (bins=100, normed=True, histtype='stepfilled')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SOS.hist_scores(rf_valid_scores, valid_Y, weights=unnormalized_valid_W)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "SOS.plot_AMS(ab_valid_scores, valid_Y, unnormalized_valid_W, weight_factor, label='adaboost')\n",
      "SOS.plot_AMS(rf_valid_scores, valid_Y, unnormalized_valid_W, weight_factor, label='random forest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Estimating your model *in nature*\n",
      "Now that you have validated your best algorithm with your best hyperparameters, you can apply it to the test set in order to have an estimate of its performance *in nature*. \n",
      "\n",
      "Remember that we split our data into three folds. So far, we've only used two of them (`train_X` and `valid_X`). \n",
      "Now that you have all the tools, you should be able to plot the test learning curve as well as the AMS curve for the test set."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Little challenge\n",
      "\n",
      "Now that you're an expert in python, scikit and machine learning, find the best model possible to find the Higgs boson!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Optional: upload your results to the Higgs challenge website"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is the current leaderboard of the challenge"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML('<iframe src=https://www.kaggle.com/c/higgs-boson/leaderboard#leaderboard-table width=1070 height=600></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you think you are getting outstanding results, you can upload apply your model on the real test set of the challenge, i.e data without labels, and look at your score.\n",
      "\n",
      "Obviously, there are no labels for this dataset because it is used to evaluate the different contenders of the Higgs challenge and to rank them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data = SOS.HiggsData('test.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SOS.generate_submission_file('submission_test.txt', random_forest, test_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}